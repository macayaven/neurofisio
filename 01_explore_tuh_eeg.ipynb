{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUH EEG Corpus - Exploratory Analysis\n",
    "\n",
    "This notebook provides a comprehensive exploration of all 7 TUH EEG corpora:\n",
    "- **TUEG** v2.0.1 - Full corpus (1,639 GB)\n",
    "- **TUAB** v3.0.1 - Abnormal EEG detection (58 GB)\n",
    "- **TUAR** v3.0.1 - Artifact detection (5.4 GB)\n",
    "- **TUEP** v3.0.0 - Epilepsy diagnosis (35 GB)\n",
    "- **TUEV** v2.0.1 - Event classification (19 GB)\n",
    "- **TUSZ** v2.0.3 - Seizure detection (81 GB)\n",
    "- **TUSL** v2.0.1 - Slowing vs seizure (1.5 GB)\n",
    "\n",
    "**Goal:** Understand data formats, distributions, and characteristics before model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import subprocess\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from neurofisio import (\n",
    "    apply_tcp_montage,\n",
    "    inspect_edf,\n",
    "    inventory_corpus,\n",
    "    load_csv_annotations,\n",
    "    load_rec_annotations,\n",
    "    load_tse_annotations,\n",
    "    parse_tuh_path,\n",
    "    plot_eeg_segment,\n",
    "    safe_read_raw_edf,\n",
    ")\n",
    "\n",
    "mne.set_log_level(\"WARNING\")\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 6)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "DATA_ROOT = Path(\"/home/carlos/workspace/neurofisio/data/tuh_eeg\")\n",
    "\n",
    "\n",
    "def is_download_running():\n",
    "    \"\"\"Check if an rsync download targeting our data dir is active.\"\"\"\n",
    "    try:\n",
    "        out = subprocess.check_output(\n",
    "            [\"pgrep\", \"-af\", \"rsync.*tuh_eeg\"], text=True, stderr=subprocess.DEVNULL\n",
    "        )\n",
    "        return bool(out.strip())\n",
    "    except subprocess.CalledProcessError:\n",
    "        return False\n",
    "\n",
    "\n",
    "DOWNLOAD_ACTIVE = is_download_running()\n",
    "\n",
    "print(f\"Data root exists: {DATA_ROOT.exists()}\")\n",
    "if DOWNLOAD_ACTIVE:\n",
    "    print(\n",
    "        \"⚠ Active rsync download detected — notebook will use lightweight scanning (no heavy I/O).\"\n",
    "    )\n",
    "if DATA_ROOT.exists():\n",
    "    available = sorted(\n",
    "        [d.name for d in DATA_ROOT.iterdir() if d.is_dir() and d.name.startswith(\"tu\")]\n",
    "    )\n",
    "    print(f\"Available corpora: {available}\")\n",
    "else:\n",
    "    print(\n",
    "        \"⚠ Data root not found — download corpora first. Notebook will skip data-dependent cells.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_config = {\n",
    "    \"TUSL\": DATA_ROOT / \"tusl\",\n",
    "    \"TUAR\": DATA_ROOT / \"tuar\",\n",
    "    \"TUEV\": DATA_ROOT / \"tuev\",\n",
    "    \"TUEP\": DATA_ROOT / \"tuep\",\n",
    "    \"TUAB\": DATA_ROOT / \"tuab\",\n",
    "    \"TUSZ\": DATA_ROOT / \"tusz\",\n",
    "    \"TUEG\": DATA_ROOT / \"tueg\",\n",
    "}\n",
    "\n",
    "inventories = []\n",
    "if DATA_ROOT.exists():\n",
    "    for name, path in corpora_config.items():\n",
    "        if not path.exists():\n",
    "            print(f\"Skipping {name} (not yet downloaded)\")\n",
    "            continue\n",
    "        try:\n",
    "            has_edfs = any(path.rglob(\"*.edf\"))\n",
    "        except Exception:\n",
    "            has_edfs = False\n",
    "        if has_edfs:\n",
    "            print(f\"Scanning {name}...\")\n",
    "            inv = inventory_corpus(path, name)\n",
    "            inventories.append(inv)\n",
    "            print(f\"  {inv['edf_files']} EDF files, {inv['subjects']} subjects\")\n",
    "        else:\n",
    "            print(f\"Skipping {name} (download in progress or empty)\")\n",
    "else:\n",
    "    print(\"Data root not found — skipping inventory.\")\n",
    "\n",
    "if inventories:\n",
    "    inv_df = pd.DataFrame(inventories)\n",
    "    inv_df.set_index(\"corpus\", inplace=True)\n",
    "    display(\n",
    "        inv_df[\n",
    "            [\n",
    "                \"edf_files\",\n",
    "                \"csv_files\",\n",
    "                \"csv_bi_files\",\n",
    "                \"tse_files\",\n",
    "                \"lab_files\",\n",
    "                \"rec_files\",\n",
    "                \"subjects\",\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    inv_df = pd.DataFrame()\n",
    "    print(\"No corpora with EDF files found yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDF File Structure Deep Dive\n",
    "\n",
    "Inspect EDF headers across corpora: channels, sampling rates, durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample N files from each available corpus to characterize EDF properties\n",
    "N_SAMPLE = 50\n",
    "\n",
    "edf_stats = []\n",
    "for inv in inventories:\n",
    "    corpus_name = inv[\"corpus\"]\n",
    "    corpus_path = corpora_config[corpus_name]\n",
    "    all_edfs = sorted(glob.glob(str(corpus_path / \"**/*.edf\"), recursive=True))\n",
    "    if not all_edfs:\n",
    "        continue\n",
    "    sample = np.random.choice(all_edfs, min(N_SAMPLE, len(all_edfs)), replace=False)\n",
    "\n",
    "    for edf_path in tqdm(sample, desc=corpus_name):\n",
    "        info = inspect_edf(edf_path)\n",
    "        if \"error\" not in info:\n",
    "            edf_stats.append(\n",
    "                {\n",
    "                    \"corpus\": corpus_name,\n",
    "                    \"n_channels\": info[\"n_channels\"],\n",
    "                    \"duration_min\": info[\"duration_sec\"] / 60,\n",
    "                    \"sfreq\": info[\"sample_freqs\"][0] if info[\"sample_freqs\"] else None,\n",
    "                    \"path\": edf_path,\n",
    "                }\n",
    "            )\n",
    "\n",
    "edf_df = pd.DataFrame(edf_stats)\n",
    "if not edf_df.empty:\n",
    "    print(f\"\\nSampled {len(edf_df)} EDF files across {edf_df['corpus'].nunique()} corpora\")\n",
    "    display(\n",
    "        edf_df.groupby(\"corpus\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"n_channels\": [\"mean\", \"min\", \"max\"],\n",
    "                \"duration_min\": [\"mean\", \"min\", \"max\"],\n",
    "                \"sfreq\": [\"mean\", \"min\", \"max\"],\n",
    "            }\n",
    "        )\n",
    "        .round(1)\n",
    "    )\n",
    "else:\n",
    "    print(\"No EDF files could be read — corpora may still be downloading.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions\n",
    "if not edf_df.empty:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    for corpus in edf_df[\"corpus\"].unique():\n",
    "        subset = edf_df[edf_df[\"corpus\"] == corpus]\n",
    "        axes[0].hist(subset[\"n_channels\"], bins=20, alpha=0.6, label=corpus)\n",
    "        axes[1].hist(subset[\"duration_min\"], bins=20, alpha=0.6, label=corpus)\n",
    "        axes[2].hist(subset[\"sfreq\"], bins=20, alpha=0.6, label=corpus)\n",
    "\n",
    "    axes[0].set_xlabel(\"Number of Channels\")\n",
    "    axes[0].set_title(\"Channel Count Distribution\")\n",
    "    axes[0].legend()\n",
    "    axes[1].set_xlabel(\"Duration (minutes)\")\n",
    "    axes[1].set_title(\"Recording Duration Distribution\")\n",
    "    axes[2].set_xlabel(\"Sampling Frequency (Hz)\")\n",
    "    axes[2].set_title(\"Sampling Rate Distribution\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(DATA_ROOT.parent / \"edf_distributions.png\"), bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No EDF data to plot — skipping distributions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Signal Visualization\n",
    "\n",
    "Load and plot actual EEG signals from each corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one sample from each available corpus\n",
    "for inv in inventories:\n",
    "    if not inv[\"sample_edf\"]:\n",
    "        continue\n",
    "    edf_path = inv[\"sample_edf\"]\n",
    "    corpus = inv[\"corpus\"]\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"Corpus: {corpus} | File: {Path(edf_path).name}\")\n",
    "\n",
    "    raw = safe_read_raw_edf(edf_path)\n",
    "    if raw is None:\n",
    "        print(f\"  Could not read {Path(edf_path).name} (file may be incomplete)\")\n",
    "        continue\n",
    "    print(\n",
    "        f\"  Channels: {raw.info['nchan']}, Sfreq: {raw.info['sfreq']} Hz, Duration: {raw.times[-1]:.0f}s\"\n",
    "    )\n",
    "\n",
    "    # Apply TCP montage\n",
    "    tcp_raw = apply_tcp_montage(raw)\n",
    "    if tcp_raw is not None:\n",
    "        fig = plot_eeg_segment(\n",
    "            tcp_raw,\n",
    "            start_sec=10,\n",
    "            duration_sec=10,\n",
    "            title=f\"{corpus}: {Path(edf_path).stem} (TCP montage, 10s window)\",\n",
    "        )\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"  Could not apply TCP montage, plotting raw channels\")\n",
    "        fig = plot_eeg_segment(\n",
    "            raw,\n",
    "            start_sec=10,\n",
    "            duration_sec=10,\n",
    "            title=f\"{corpus}: {Path(edf_path).stem} (raw channels, 10s window)\",\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "if not inventories:\n",
    "    print(\"No corpora available to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Annotation Analysis by Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 TUAR - Artifact Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuar_path = DATA_ROOT / \"tuar\"\n",
    "if tuar_path.exists():\n",
    "    tuar_csvs = sorted(tuar_path.rglob(\"*.csv\"))\n",
    "    tuar_csvs = [f for f in tuar_csvs if \"_seiz\" not in f.name]\n",
    "\n",
    "    if tuar_csvs:\n",
    "        all_labels = []\n",
    "        all_durations = []\n",
    "        for csv_path in tqdm(tuar_csvs[:100], desc=\"TUAR annotations\"):\n",
    "            df, meta = load_csv_annotations(csv_path)\n",
    "            if \"label\" in df.columns and \"start_time\" in df.columns and \"stop_time\" in df.columns:\n",
    "                df[\"duration\"] = df[\"stop_time\"] - df[\"start_time\"]\n",
    "                all_labels.extend(df[\"label\"].tolist())\n",
    "                all_durations.extend(df[\"duration\"].tolist())\n",
    "\n",
    "        label_counts = Counter(all_labels)\n",
    "        print(f\"TUAR: {len(tuar_csvs)} annotation files, {len(all_labels)} total events\")\n",
    "\n",
    "        if label_counts and all_durations:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "            labels, counts = zip(*label_counts.most_common(15))\n",
    "            ax1.barh(range(len(labels)), counts, color=\"steelblue\")\n",
    "            ax1.set_yticks(range(len(labels)))\n",
    "            ax1.set_yticklabels(labels)\n",
    "            ax1.set_xlabel(\"Count\")\n",
    "            ax1.set_title(\"TUAR: Artifact Type Distribution\")\n",
    "            ax1.invert_yaxis()\n",
    "\n",
    "            ax2.hist(all_durations, bins=50, color=\"coral\", edgecolor=\"white\")\n",
    "            ax2.set_xlabel(\"Duration (seconds)\")\n",
    "            ax2.set_title(\"TUAR: Artifact Event Duration\")\n",
    "            ax2.set_xlim(0, min(30, np.percentile(all_durations, 99)))\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"TUAR directory exists but no CSV annotations yet (download in progress?)\")\n",
    "else:\n",
    "    print(\"TUAR not available yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 TUSZ - Seizure Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tusz_path = DATA_ROOT / \"tusz\"\n",
    "if tusz_path.exists():\n",
    "    csv_bi_candidates = list(tusz_path.rglob(\"*.csv_bi\"))\n",
    "    if csv_bi_candidates:\n",
    "        seizure_stats = {\n",
    "            \"train\": defaultdict(int),\n",
    "            \"dev\": defaultdict(int),\n",
    "            \"eval\": defaultdict(int),\n",
    "        }\n",
    "\n",
    "        for split in [\"train\", \"dev\", \"eval\"]:\n",
    "            split_path = tusz_path / \"edf\" / split\n",
    "            if not split_path.exists():\n",
    "                continue\n",
    "            csv_bi_files = sorted(split_path.rglob(\"*.csv_bi\"))\n",
    "\n",
    "            for csv_path in tqdm(csv_bi_files[:200], desc=f\"TUSZ {split}\"):\n",
    "                df, meta = load_csv_annotations(csv_path)\n",
    "                if \"label\" in df.columns:\n",
    "                    for label in df[\"label\"].unique():\n",
    "                        seizure_stats[split][label] += (df[\"label\"] == label).sum()\n",
    "\n",
    "        print(\"\\nTUSZ Label Distribution (sampled):\")\n",
    "        for split, counts in seizure_stats.items():\n",
    "            total = sum(counts.values())\n",
    "            if total > 0:\n",
    "                print(f\"  {split}: {dict(counts)} (total: {total})\")\n",
    "\n",
    "        # Also check multi-class annotations\n",
    "        edf_dir = tusz_path / \"edf\"\n",
    "        if edf_dir.exists():\n",
    "            csv_files = sorted(edf_dir.rglob(\"*.csv\"))\n",
    "            csv_files = [f for f in csv_files if not f.name.endswith(\".csv_bi\")]\n",
    "            seizure_types = Counter()\n",
    "            for csv_path in tqdm(csv_files[:300], desc=\"TUSZ seizure types\"):\n",
    "                df, _ = load_csv_annotations(csv_path)\n",
    "                if \"label\" in df.columns:\n",
    "                    for label in df[\"label\"]:\n",
    "                        if label != \"bckg\":\n",
    "                            seizure_types[label] += 1\n",
    "\n",
    "            if seizure_types:\n",
    "                print(f\"\\nSeizure type distribution (from {min(300, len(csv_files))} files):\")\n",
    "                for label, count in seizure_types.most_common():\n",
    "                    print(f\"  {label}: {count}\")\n",
    "    else:\n",
    "        print(\"TUSZ directory exists but no .csv_bi annotations yet (download in progress?)\")\n",
    "else:\n",
    "    print(\"TUSZ not available yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 TUAB - Normal/Abnormal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuab_path = DATA_ROOT / \"tuab\"\n",
    "if tuab_path.exists():\n",
    "    edf_candidates = list(tuab_path.rglob(\"*.edf\"))\n",
    "    if edf_candidates:\n",
    "        tuab_stats = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        for split in [\"train\", \"eval\"]:\n",
    "            for label in [\"normal\", \"abnormal\"]:\n",
    "                label_path = tuab_path / \"edf\" / split / label\n",
    "                if label_path.exists():\n",
    "                    n_files = len(list(label_path.rglob(\"*.edf\")))\n",
    "                    tuab_stats[split][label] = n_files\n",
    "\n",
    "        if tuab_stats:\n",
    "            print(\"TUAB Normal/Abnormal Distribution:\")\n",
    "            tuab_summary = pd.DataFrame(tuab_stats).T\n",
    "            if \"abnormal\" in tuab_summary.columns and \"normal\" in tuab_summary.columns:\n",
    "                tuab_summary[\"total\"] = tuab_summary.sum(axis=1)\n",
    "                tuab_summary[\"abnormal_pct\"] = (\n",
    "                    tuab_summary[\"abnormal\"] / tuab_summary[\"total\"] * 100\n",
    "                ).round(1)\n",
    "            display(tuab_summary)\n",
    "\n",
    "        # Duration distribution by class\n",
    "        dur_data = []\n",
    "        for split in [\"train\", \"eval\"]:\n",
    "            for label in [\"normal\", \"abnormal\"]:\n",
    "                label_path = tuab_path / \"edf\" / split / label\n",
    "                if not label_path.exists():\n",
    "                    continue\n",
    "                edfs = sorted(label_path.rglob(\"*.edf\"))\n",
    "                for edf in edfs[:50]:\n",
    "                    info = inspect_edf(edf)\n",
    "                    if \"error\" not in info:\n",
    "                        dur_data.append(\n",
    "                            {\n",
    "                                \"split\": split,\n",
    "                                \"label\": label,\n",
    "                                \"duration_min\": info[\"duration_sec\"] / 60,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "        if dur_data:\n",
    "            dur_df = pd.DataFrame(dur_data)\n",
    "            fig, ax = plt.subplots(figsize=(10, 5))\n",
    "            for label in [\"normal\", \"abnormal\"]:\n",
    "                subset = dur_df[dur_df[\"label\"] == label]\n",
    "                if not subset.empty:\n",
    "                    ax.hist(subset[\"duration_min\"], bins=30, alpha=0.6, label=label)\n",
    "            ax.set_xlabel(\"Duration (minutes)\")\n",
    "            ax.set_title(\"TUAB: Recording Duration by Class\")\n",
    "            ax.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"TUAB directory exists but no EDF files yet (download in progress?)\")\n",
    "else:\n",
    "    print(\"TUAB not available yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 TUEV - Event Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuev_path = DATA_ROOT / \"tuev\"\n",
    "if tuev_path.exists():\n",
    "    rec_files = sorted(tuev_path.rglob(\"*.rec\"))\n",
    "    if rec_files:\n",
    "        event_counts = Counter()\n",
    "\n",
    "        for rec_path in tqdm(rec_files[:200], desc=\"TUEV events\"):\n",
    "            df = load_rec_annotations(rec_path)\n",
    "            if not df.empty:\n",
    "                event_counts.update(df[\"label\"].tolist())\n",
    "\n",
    "        print(f\"TUEV: {len(rec_files)} .rec files\")\n",
    "        print(\"Event distribution:\")\n",
    "\n",
    "        if event_counts:\n",
    "            fig, ax = plt.subplots(figsize=(10, 4))\n",
    "            labels, counts = zip(*event_counts.most_common())\n",
    "            colors = {\n",
    "                \"spsw\": \"#e74c3c\",\n",
    "                \"gped\": \"#e67e22\",\n",
    "                \"pled\": \"#f39c12\",\n",
    "                \"eyem\": \"#3498db\",\n",
    "                \"artf\": \"#95a5a6\",\n",
    "                \"bckg\": \"#2ecc71\",\n",
    "            }\n",
    "            bar_colors = [colors.get(l, \"#95a5a6\") for l in labels]\n",
    "            ax.bar(labels, counts, color=bar_colors)\n",
    "            ax.set_ylabel(\"Count\")\n",
    "            ax.set_title(\"TUEV: Event Type Distribution\")\n",
    "            for i, (_l, c) in enumerate(zip(labels, counts)):\n",
    "                ax.text(i, c + max(counts) * 0.01, str(c), ha=\"center\", fontsize=9)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"TUEV directory exists but no .rec files yet (download in progress?)\")\n",
    "else:\n",
    "    print(\"TUEV not available yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 TUSL - Slowing Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tusl_path = DATA_ROOT / \"tusl\"\n",
    "if tusl_path.exists():\n",
    "    tse_files = sorted(tusl_path.rglob(\"*.tse\"))\n",
    "    tse_agg_files = sorted(tusl_path.rglob(\"*.tse_agg\"))\n",
    "\n",
    "    if tse_files:\n",
    "        label_counts = Counter()\n",
    "        for tse_path in tqdm(tse_files, desc=\"TUSL annotations\"):\n",
    "            df = load_tse_annotations(tse_path)\n",
    "            if not df.empty:\n",
    "                label_counts.update(df[\"label\"].tolist())\n",
    "\n",
    "        print(f\"TUSL: {len(tse_files)} .tse files, {len(tse_agg_files)} .tse_agg files\")\n",
    "        print(f\"Labels: {dict(label_counts)}\")\n",
    "\n",
    "        if label_counts:\n",
    "            fig, ax = plt.subplots(figsize=(8, 4))\n",
    "            labels, counts = zip(*label_counts.most_common())\n",
    "            colors = {\"seiz\": \"#e74c3c\", \"slow\": \"#f39c12\", \"bckg\": \"#2ecc71\"}\n",
    "            ax.bar(labels, counts, color=[colors.get(l, \"#95a5a6\") for l in labels])\n",
    "            ax.set_title(\"TUSL: Label Distribution\")\n",
    "            ax.set_ylabel(\"Count\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"TUSL directory exists but no .tse files yet (download in progress?)\")\n",
    "else:\n",
    "    print(\"TUSL not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 TUEP - Epilepsy Corpus with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuep_path = DATA_ROOT / \"tuep\"\n",
    "if tuep_path.exists():\n",
    "    # Check for metadata spreadsheet\n",
    "    metadata_path = tuep_path / \"DOCS\" / \"metadata_v00r.xlsx\"\n",
    "    if metadata_path.exists():\n",
    "        try:\n",
    "            meta_df = pd.read_excel(metadata_path)\n",
    "            print(f\"TUEP Metadata: {len(meta_df)} rows, {len(meta_df.columns)} columns\")\n",
    "            print(f\"Columns: {list(meta_df.columns)}\")\n",
    "            display(meta_df.head(10))\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read metadata: {e}\")\n",
    "\n",
    "    # Count files per class\n",
    "    found_any = False\n",
    "    for cls in [\"00_epilepsy\", \"01_no_epilepsy\"]:\n",
    "        cls_path = tuep_path / cls\n",
    "        if cls_path.exists():\n",
    "            found_any = True\n",
    "            n_edfs = len(list(cls_path.rglob(\"*.edf\")))\n",
    "            n_subjects = (\n",
    "                len([d for d in cls_path.iterdir() if d.is_dir()]) if cls_path.is_dir() else 0\n",
    "            )\n",
    "            print(f\"  {cls}: {n_edfs} EDF files, {n_subjects} subjects\")\n",
    "    if not found_any:\n",
    "        print(\"TUEP directory exists but class folders not found yet (download in progress?)\")\n",
    "else:\n",
    "    print(\"TUEP not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Signal Quality & Spectral Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a representative file — try TUSL first (smallest), fall back to any available corpus\n",
    "sample_edfs = sorted(glob.glob(str(DATA_ROOT / \"tusl\" / \"**/*.edf\"), recursive=True))\n",
    "if not sample_edfs and inventories:\n",
    "    # Fall back to first corpus that has an EDF\n",
    "    for inv in inventories:\n",
    "        if inv[\"sample_edf\"]:\n",
    "            sample_edfs = [inv[\"sample_edf\"]]\n",
    "            break\n",
    "\n",
    "if sample_edfs:\n",
    "    sample_edf = sample_edfs[0]\n",
    "    raw = safe_read_raw_edf(sample_edf)\n",
    "\n",
    "    if raw is not None:\n",
    "        tcp = apply_tcp_montage(raw)\n",
    "\n",
    "        if tcp is not None:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "            # PSD\n",
    "            psd = tcp.compute_psd(fmin=0.5, fmax=50, method=\"welch\", verbose=False)\n",
    "            psd.plot(axes=axes[0], show=False, spatial_colors=True)\n",
    "            axes[0].set_title(\"Power Spectral Density (TCP montage)\")\n",
    "\n",
    "            # Spectrogram of one channel\n",
    "            data = tcp.get_data(picks=[0])[0]\n",
    "            sfreq = tcp.info[\"sfreq\"]\n",
    "            axes[1].specgram(\n",
    "                data,\n",
    "                NFFT=int(sfreq * 2),\n",
    "                Fs=sfreq,\n",
    "                noverlap=int(sfreq),\n",
    "                cmap=\"viridis\",\n",
    "                vmin=-30,\n",
    "                vmax=10,\n",
    "            )\n",
    "            axes[1].set_ylabel(\"Frequency (Hz)\")\n",
    "            axes[1].set_xlabel(\"Time (s)\")\n",
    "            axes[1].set_ylim(0, 50)\n",
    "            axes[1].set_title(f\"Spectrogram: {tcp.ch_names[0]}\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(str(DATA_ROOT.parent / \"spectral_analysis.png\"), bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Could not apply TCP montage to sample file\")\n",
    "    else:\n",
    "        print(f\"Could not read {sample_edf} (file may be incomplete)\")\n",
    "else:\n",
    "    print(\"No EDF files found — skipping spectral analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-Corpus Comparison\n",
    "\n",
    "Compare key properties across all available corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize all findings\n",
    "if inventories:\n",
    "    summary_data = []\n",
    "    for inv in inventories:\n",
    "        corpus = inv[\"corpus\"]\n",
    "        corpus_edfs = (\n",
    "            edf_df[edf_df[\"corpus\"] == corpus]\n",
    "            if not edf_df.empty and \"corpus\" in edf_df.columns\n",
    "            else pd.DataFrame()\n",
    "        )\n",
    "\n",
    "        summary_data.append(\n",
    "            {\n",
    "                \"Corpus\": corpus,\n",
    "                \"EDF Files\": inv[\"edf_files\"],\n",
    "                \"Subjects\": inv[\"subjects\"],\n",
    "                \"Annotation Files\": inv[\"csv_files\"]\n",
    "                + inv[\"tse_files\"]\n",
    "                + inv[\"rec_files\"]\n",
    "                + inv[\"lab_files\"],\n",
    "                \"Avg Duration (min)\": corpus_edfs[\"duration_min\"].mean()\n",
    "                if not corpus_edfs.empty\n",
    "                else None,\n",
    "                \"Avg Channels\": corpus_edfs[\"n_channels\"].mean()\n",
    "                if not corpus_edfs.empty\n",
    "                else None,\n",
    "                \"Primary Sfreq (Hz)\": corpus_edfs[\"sfreq\"].mode().iloc[0]\n",
    "                if not corpus_edfs.empty and not corpus_edfs[\"sfreq\"].mode().empty\n",
    "                else None,\n",
    "                \"Montages\": \", \".join(inv[\"montages\"].keys()) if inv[\"montages\"] else \"N/A\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data).set_index(\"Corpus\")\n",
    "    display(summary_df)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXPLORATION COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "if inventories:\n",
    "    print(f\"Corpora explored: {len(inventories)}\")\n",
    "    print(f\"Total EDF files across corpora: {sum(inv['edf_files'] for inv in inventories)}\")\n",
    "    print(\n",
    "        f\"Total unique subjects: {sum(inv['subjects'] for inv in inventories)} (with overlap between corpora)\"\n",
    "    )\n",
    "else:\n",
    "    print(\"No corpora available yet. Re-run after downloading data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Interactive EEG Explorer\n\nSelect a corpus, browse subjects, preview file info, and open recordings — all from dropdowns.\n- **Plot in Notebook**: inline 10-second TCP montage preview\n- **Open Qt Viewer**: full scrollable EEG browser in a separate window (requires display/X11)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import HTML, clear_output, display\n",
    "\n",
    "# ── Corpus metadata ──────────────────────────────────────────────────────────\n",
    "CORPUS_META = {\n",
    "    \"TUSL\": {\n",
    "        \"desc\": \"Slowing vs Seizure differentiation\",\n",
    "        \"size\": \"1.5 GB\",\n",
    "        \"version\": \"v2.0.1\",\n",
    "        \"labels\": \"seiz, slow, bckg\",\n",
    "        \"ann_ext\": \".tse\",\n",
    "    },\n",
    "    \"TUAR\": {\n",
    "        \"desc\": \"Per-channel artifact detection\",\n",
    "        \"size\": \"5.4 GB\",\n",
    "        \"version\": \"v3.0.1\",\n",
    "        \"labels\": \"eyem, chew, shiv, musc, elec, ...\",\n",
    "        \"ann_ext\": \".csv\",\n",
    "    },\n",
    "    \"TUEV\": {\n",
    "        \"desc\": \"6-class EEG event classification\",\n",
    "        \"size\": \"19 GB\",\n",
    "        \"version\": \"v2.0.1\",\n",
    "        \"labels\": \"spsw, gped, pled, eyem, artf, bckg\",\n",
    "        \"ann_ext\": \".rec\",\n",
    "    },\n",
    "    \"TUEP\": {\n",
    "        \"desc\": \"Epilepsy / no-epilepsy diagnosis\",\n",
    "        \"size\": \"35 GB\",\n",
    "        \"version\": \"v3.0.0\",\n",
    "        \"labels\": \"epilepsy, no_epilepsy\",\n",
    "        \"ann_ext\": \".csv\",\n",
    "    },\n",
    "    \"TUAB\": {\n",
    "        \"desc\": \"Binary normal / abnormal EEG\",\n",
    "        \"size\": \"58 GB\",\n",
    "        \"version\": \"v3.0.1\",\n",
    "        \"labels\": \"normal, abnormal (by folder)\",\n",
    "        \"ann_ext\": None,\n",
    "    },\n",
    "    \"TUSZ\": {\n",
    "        \"desc\": \"Seizure detection benchmark\",\n",
    "        \"size\": \"81 GB\",\n",
    "        \"version\": \"v2.0.3\",\n",
    "        \"labels\": \"seiz, bckg (+ seizure types)\",\n",
    "        \"ann_ext\": \".csv_bi\",\n",
    "    },\n",
    "    \"TUEG\": {\n",
    "        \"desc\": \"Full TUH EEG Corpus (unlabeled)\",\n",
    "        \"size\": \"1,639 GB\",\n",
    "        \"version\": \"v2.0.1\",\n",
    "        \"labels\": \"N/A\",\n",
    "        \"ann_ext\": None,\n",
    "    },\n",
    "}\n",
    "\n",
    "# ── Lazy per-subject index with cache ────────────────────────────────────────\n",
    "_subject_cache = {}\n",
    "\n",
    "\n",
    "def _scan_subjects(corpus_name):\n",
    "    \"\"\"Scan corpus EDF files grouped by subject. Cached after first call.\"\"\"\n",
    "    if corpus_name in _subject_cache:\n",
    "        return _subject_cache[corpus_name]\n",
    "    path = corpora_config.get(corpus_name)\n",
    "    if not path or not path.exists():\n",
    "        return {}\n",
    "    subjects = {}\n",
    "    for edf in sorted(path.rglob(\"*.edf\")):\n",
    "        meta = parse_tuh_path(edf)\n",
    "        if meta:\n",
    "            subjects.setdefault(meta[\"subject_id\"], []).append(meta)\n",
    "    _subject_cache[corpus_name] = subjects\n",
    "    return subjects\n",
    "\n",
    "\n",
    "# ── Available corpora (from inventory, already computed) ─────────────────────\n",
    "_available = [inv[\"corpus\"] for inv in inventories] if inventories else []\n",
    "\n",
    "# ── Widgets ──────────────────────────────────────────────────────────────────\n",
    "_style = {\"description_width\": \"70px\"}\n",
    "\n",
    "corpus_dd = widgets.Dropdown(\n",
    "    options=[\"\", *_available],\n",
    "    value=\"\",\n",
    "    description=\"Corpus:\",\n",
    "    style=_style,\n",
    "    layout=widgets.Layout(width=\"260px\"),\n",
    ")\n",
    "subject_dd = widgets.Dropdown(\n",
    "    options=[\"\"],\n",
    "    value=\"\",\n",
    "    description=\"Subject:\",\n",
    "    style=_style,\n",
    "    layout=widgets.Layout(width=\"260px\"),\n",
    ")\n",
    "file_dd = widgets.Dropdown(\n",
    "    options=[\"\"],\n",
    "    value=\"\",\n",
    "    description=\"File:\",\n",
    "    style=_style,\n",
    "    layout=widgets.Layout(width=\"420px\"),\n",
    ")\n",
    "\n",
    "plot_btn = widgets.Button(\n",
    "    description=\" Plot in Notebook\",\n",
    "    icon=\"line-chart\",\n",
    "    button_style=\"info\",\n",
    "    layout=widgets.Layout(width=\"180px\", height=\"36px\"),\n",
    ")\n",
    "viewer_btn = widgets.Button(\n",
    "    description=\" Open Qt Viewer\",\n",
    "    icon=\"desktop\",\n",
    "    button_style=\"success\",\n",
    "    layout=widgets.Layout(width=\"180px\", height=\"36px\"),\n",
    ")\n",
    "\n",
    "overview_out = widgets.Output(\n",
    "    layout=widgets.Layout(\n",
    "        border=\"1px solid #ccc\",\n",
    "        padding=\"10px\",\n",
    "        min_height=\"120px\",\n",
    "        width=\"100%\",\n",
    "    )\n",
    ")\n",
    "file_info_out = widgets.Output(\n",
    "    layout=widgets.Layout(\n",
    "        border=\"1px solid #ccc\",\n",
    "        padding=\"10px\",\n",
    "        min_height=\"120px\",\n",
    "        width=\"100%\",\n",
    "    )\n",
    ")\n",
    "plot_out = widgets.Output(layout=widgets.Layout(width=\"100%\"))\n",
    "status_label = widgets.HTML(value=\"<i>Select a corpus to begin.</i>\")\n",
    "\n",
    "# ── Internal state ───────────────────────────────────────────────────────────\n",
    "_state = {\"subjects\": {}, \"files\": [], \"raw\": None, \"tcp\": None, \"path\": None}\n",
    "\n",
    "\n",
    "# ── Callbacks ────────────────────────────────────────────────────────────────\n",
    "def _on_corpus(change):\n",
    "    corpus = change[\"new\"]\n",
    "    # Reset downstream\n",
    "    _state[\"raw\"] = _state[\"tcp\"] = _state[\"path\"] = None\n",
    "    file_dd.options = [\"\"]\n",
    "    file_dd.value = \"\"\n",
    "    with file_info_out:\n",
    "        clear_output()\n",
    "    with plot_out:\n",
    "        clear_output()\n",
    "\n",
    "    if not corpus:\n",
    "        subject_dd.options = [\"\"]\n",
    "        with overview_out:\n",
    "            clear_output()\n",
    "        status_label.value = \"<i>Select a corpus to begin.</i>\"\n",
    "        return\n",
    "\n",
    "    status_label.value = f\"<i>Scanning {corpus} subjects...</i>\"\n",
    "    subjects = _scan_subjects(corpus)\n",
    "    _state[\"subjects\"] = subjects\n",
    "\n",
    "    # Populate subject dropdown\n",
    "    sorted_sids = sorted(subjects.keys())\n",
    "    subject_dd.options = [\"\", *sorted_sids]\n",
    "    subject_dd.value = \"\"\n",
    "\n",
    "    # Overview panel\n",
    "    meta = CORPUS_META.get(corpus, {})\n",
    "    inv = next((i for i in inventories if i[\"corpus\"] == corpus), None)\n",
    "    with overview_out:\n",
    "        clear_output(wait=True)\n",
    "        lines = [\n",
    "            f\"<b>{corpus}</b> {meta.get('version', '')} &mdash; {meta.get('size', '?')}\",\n",
    "            f\"<i>{meta.get('desc', '')}</i>\",\n",
    "            f\"<b>EDF files:</b> {inv['edf_files'] if inv else '?'} &nbsp;|&nbsp; \"\n",
    "            f\"<b>Subjects:</b> {len(sorted_sids)}\",\n",
    "            f\"<b>Labels:</b> {meta.get('labels', 'N/A')}\",\n",
    "        ]\n",
    "        if inv and inv[\"montages\"]:\n",
    "            montage_str = \", \".join(f\"{k} ({v})\" for k, v in inv[\"montages\"].items())\n",
    "            lines.append(f\"<b>Montages:</b> {montage_str}\")\n",
    "        display(HTML(\"<br>\".join(lines)))\n",
    "\n",
    "    status_label.value = f\"<b>{corpus}</b>: {len(sorted_sids)} subjects ready.\"\n",
    "\n",
    "\n",
    "def _on_subject(change):\n",
    "    sid = change[\"new\"]\n",
    "    _state[\"raw\"] = _state[\"tcp\"] = _state[\"path\"] = None\n",
    "    with file_info_out:\n",
    "        clear_output()\n",
    "    with plot_out:\n",
    "        clear_output()\n",
    "\n",
    "    if not sid:\n",
    "        file_dd.options = [\"\"]\n",
    "        return\n",
    "\n",
    "    files = _state[\"subjects\"].get(sid, [])\n",
    "    _state[\"files\"] = files\n",
    "    labels = [f\"{Path(f['path']).stem}  ({f['montage'] or '?'})\" for f in files]\n",
    "    file_dd.options = [\"\", *labels]\n",
    "    file_dd.value = \"\"\n",
    "    status_label.value = f\"Subject <b>{sid}</b>: {len(files)} file(s).\"\n",
    "\n",
    "\n",
    "def _on_file(change):\n",
    "    sel = change[\"new\"]\n",
    "    _state[\"raw\"] = _state[\"tcp\"] = _state[\"path\"] = None\n",
    "    with plot_out:\n",
    "        clear_output()\n",
    "\n",
    "    if not sel:\n",
    "        with file_info_out:\n",
    "            clear_output()\n",
    "        return\n",
    "\n",
    "    idx = (file_dd.options).index(sel) - 1  # offset for leading ''\n",
    "    meta = _state[\"files\"][idx]\n",
    "    edf_path = meta[\"path\"]\n",
    "    _state[\"path\"] = edf_path\n",
    "\n",
    "    info = inspect_edf(edf_path)\n",
    "    with file_info_out:\n",
    "        clear_output(wait=True)\n",
    "        if \"error\" in info:\n",
    "            display(\n",
    "                HTML(\n",
    "                    f\"<span style='color:red'>Cannot read file (may be incomplete):</span><br>{info['error']}\"\n",
    "                )\n",
    "            )\n",
    "            return\n",
    "        dur_min = info[\"duration_sec\"] / 60\n",
    "        sfreqs = info[\"sample_freqs\"]\n",
    "        sfreq_str = f\"{sfreqs[0]:.0f} Hz\" if sfreqs else \"?\"\n",
    "        lines = [\n",
    "            f\"<b>{Path(edf_path).name}</b>\",\n",
    "            f\"<b>Channels:</b> {info['n_channels']} &nbsp;|&nbsp; \"\n",
    "            f\"<b>Sfreq:</b> {sfreq_str} &nbsp;|&nbsp; \"\n",
    "            f\"<b>Duration:</b> {dur_min:.1f} min\",\n",
    "            f\"<b>Montage:</b> {meta['montage'] or 'unknown'}\",\n",
    "            f\"<b>Subject:</b> {meta['subject_id']} &nbsp;|&nbsp; \"\n",
    "            f\"<b>Session:</b> s{meta['session_num']:03d} &nbsp;|&nbsp; \"\n",
    "            f\"<b>Token:</b> t{meta['token_num']:03d}\",\n",
    "        ]\n",
    "        # Check for annotation files alongside the EDF\n",
    "        edf_p = Path(edf_path)\n",
    "        ann_exts = [\".csv\", \".csv_bi\", \".tse\", \".tse_agg\", \".lbl\", \".lbl_agg\", \".rec\", \".lab\"]\n",
    "        found_ann = [ext for ext in ann_exts if edf_p.with_suffix(ext).exists()]\n",
    "        if found_ann:\n",
    "            lines.append(f\"<b>Annotations:</b> {', '.join(found_ann)}\")\n",
    "        else:\n",
    "            lines.append(\"<b>Annotations:</b> none found\")\n",
    "        display(HTML(\"<br>\".join(lines)))\n",
    "\n",
    "    status_label.value = f\"Ready: {Path(edf_path).name}\"\n",
    "\n",
    "\n",
    "def _on_plot(btn):\n",
    "    if not _state[\"path\"]:\n",
    "        with plot_out:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Select a file first.\")\n",
    "        return\n",
    "\n",
    "    with plot_out:\n",
    "        clear_output(wait=True)\n",
    "        status_label.value = \"<i>Loading EDF...</i>\"\n",
    "        raw = safe_read_raw_edf(_state[\"path\"])\n",
    "        if raw is None:\n",
    "            print(\"Could not read file (may be incomplete).\")\n",
    "            status_label.value = \"Load failed.\"\n",
    "            return\n",
    "        _state[\"raw\"] = raw\n",
    "        tcp = apply_tcp_montage(raw)\n",
    "        _state[\"tcp\"] = tcp\n",
    "        target = tcp if tcp is not None else raw\n",
    "        tag = \"TCP montage\" if tcp is not None else \"raw channels\"\n",
    "\n",
    "        # Pick a start 10s in if recording is long enough\n",
    "        max_start = max(0, target.times[-1] - 10)\n",
    "        start = min(10.0, max_start)\n",
    "\n",
    "        plot_eeg_segment(\n",
    "            target, start_sec=start, duration_sec=10, title=f\"{Path(_state['path']).stem} ({tag})\"\n",
    "        )\n",
    "        plt.show()\n",
    "        status_label.value = f\"Plotted {Path(_state['path']).name} ({tag}).\"\n",
    "\n",
    "\n",
    "def _on_viewer(btn):\n",
    "    if not _state[\"path\"]:\n",
    "        status_label.value = '<span style=\"color:orange\">Select a file first.</span>'\n",
    "        return\n",
    "\n",
    "    status_label.value = \"<i>Loading into Qt viewer...</i>\"\n",
    "    raw = _state.get(\"raw\") or safe_read_raw_edf(_state[\"path\"])\n",
    "    if raw is None:\n",
    "        status_label.value = '<span style=\"color:red\">Could not read file.</span>'\n",
    "        return\n",
    "    _state[\"raw\"] = raw\n",
    "\n",
    "    tcp = _state.get(\"tcp\") or apply_tcp_montage(raw)\n",
    "    target = tcp if tcp is not None else raw\n",
    "\n",
    "    try:\n",
    "        mne.viz.set_browser_backend(\"qt\")\n",
    "        target.plot(block=False, title=Path(_state[\"path\"]).stem)\n",
    "        status_label.value = f\"Qt viewer opened for {Path(_state['path']).name}.\"\n",
    "    except Exception as e:\n",
    "        status_label.value = f'<span style=\"color:red\">Qt viewer failed: {e}</span>'\n",
    "\n",
    "\n",
    "# ── Wire up ──────────────────────────────────────────────────────────────────\n",
    "corpus_dd.observe(_on_corpus, names=\"value\")\n",
    "subject_dd.observe(_on_subject, names=\"value\")\n",
    "file_dd.observe(_on_file, names=\"value\")\n",
    "plot_btn.on_click(_on_plot)\n",
    "viewer_btn.on_click(_on_viewer)\n",
    "\n",
    "# ── Layout ───────────────────────────────────────────────────────────────────\n",
    "selectors = widgets.HBox([corpus_dd, subject_dd, file_dd], layout=widgets.Layout(gap=\"8px\"))\n",
    "buttons = widgets.HBox([plot_btn, viewer_btn], layout=widgets.Layout(gap=\"8px\"))\n",
    "panels = widgets.HBox(\n",
    "    [\n",
    "        widgets.VBox(\n",
    "            [widgets.HTML(\"<b>Corpus Overview</b>\"), overview_out],\n",
    "            layout=widgets.Layout(width=\"50%\"),\n",
    "        ),\n",
    "        widgets.VBox(\n",
    "            [widgets.HTML(\"<b>File Details</b>\"), file_info_out],\n",
    "            layout=widgets.Layout(width=\"50%\"),\n",
    "        ),\n",
    "    ],\n",
    "    layout=widgets.Layout(gap=\"12px\"),\n",
    ")\n",
    "\n",
    "ui = widgets.VBox(\n",
    "    [\n",
    "        selectors,\n",
    "        panels,\n",
    "        widgets.HBox(\n",
    "            [buttons, status_label], layout=widgets.Layout(gap=\"16px\", align_items=\"center\")\n",
    "        ),\n",
    "        plot_out,\n",
    "    ],\n",
    "    layout=widgets.Layout(gap=\"10px\", padding=\"8px\"),\n",
    ")\n",
    "\n",
    "display(ui)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}