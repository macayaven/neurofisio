{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUH EEG Corpus - Exploratory Analysis\n",
    "\n",
    "This notebook provides a comprehensive exploration of all 7 TUH EEG corpora:\n",
    "- **TUEG** v2.0.1 - Full corpus (1,639 GB)\n",
    "- **TUAB** v3.0.1 - Abnormal EEG detection (58 GB)\n",
    "- **TUAR** v3.0.1 - Artifact detection (5.4 GB)\n",
    "- **TUEP** v3.0.0 - Epilepsy diagnosis (35 GB)\n",
    "- **TUEV** v2.0.1 - Event classification (19 GB)\n",
    "- **TUSZ** v2.0.3 - Seizure detection (81 GB)\n",
    "- **TUSL** v2.0.1 - Slowing vs seizure (1.5 GB)\n",
    "\n",
    "**Goal:** Understand data formats, distributions, and characteristics before model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport glob\nimport subprocess\nfrom pathlib import Path\nfrom collections import Counter, defaultdict\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport mne\nfrom tqdm import tqdm\n\nfrom neurofisio import (\n    parse_tuh_path, load_csv_annotations, load_tse_annotations,\n    load_rec_annotations, load_lab_annotations,\n    inspect_edf, safe_read_raw_edf, inventory_corpus,\n    apply_tcp_montage, plot_eeg_segment, TCP_NAMES,\n)\n\nmne.set_log_level('WARNING')\nplt.rcParams['figure.figsize'] = (16, 6)\nplt.rcParams['figure.dpi'] = 100\n\nDATA_ROOT = Path('/home/carlos/workspace/neurofisio/data/tuh_eeg')\n\ndef is_download_running():\n    \"\"\"Check if an rsync download targeting our data dir is active.\"\"\"\n    try:\n        out = subprocess.check_output(['pgrep', '-af', 'rsync.*tuh_eeg'], text=True, stderr=subprocess.DEVNULL)\n        return bool(out.strip())\n    except subprocess.CalledProcessError:\n        return False\n\nDOWNLOAD_ACTIVE = is_download_running()\n\nprint(f\"Data root exists: {DATA_ROOT.exists()}\")\nif DOWNLOAD_ACTIVE:\n    print(\"⚠ Active rsync download detected — notebook will use lightweight scanning (no heavy I/O).\")\nif DATA_ROOT.exists():\n    available = sorted([d.name for d in DATA_ROOT.iterdir() if d.is_dir() and d.name.startswith('tu')])\n    print(f\"Available corpora: {available}\")\nelse:\n    print(\"⚠ Data root not found — download corpora first. Notebook will skip data-dependent cells.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "corpora_config = {\n    'TUSL': DATA_ROOT / 'tusl',\n    'TUAR': DATA_ROOT / 'tuar',\n    'TUEV': DATA_ROOT / 'tuev',\n    'TUEP': DATA_ROOT / 'tuep',\n    'TUAB': DATA_ROOT / 'tuab',\n    'TUSZ': DATA_ROOT / 'tusz',\n    'TUEG': DATA_ROOT / 'tueg',\n}\n\ninventories = []\nif DATA_ROOT.exists():\n    for name, path in corpora_config.items():\n        if not path.exists():\n            print(f\"Skipping {name} (not yet downloaded)\")\n            continue\n        try:\n            has_edfs = any(path.rglob('*.edf'))\n        except Exception:\n            has_edfs = False\n        if has_edfs:\n            print(f\"Scanning {name}...\")\n            inv = inventory_corpus(path, name)\n            inventories.append(inv)\n            print(f\"  {inv['edf_files']} EDF files, {inv['subjects']} subjects\")\n        else:\n            print(f\"Skipping {name} (download in progress or empty)\")\nelse:\n    print(\"Data root not found — skipping inventory.\")\n\nif inventories:\n    inv_df = pd.DataFrame(inventories)\n    inv_df.set_index('corpus', inplace=True)\n    display(inv_df[['edf_files', 'csv_files', 'csv_bi_files', 'tse_files', 'lab_files', 'rec_files', 'subjects']])\nelse:\n    inv_df = pd.DataFrame()\n    print(\"No corpora with EDF files found yet.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDF File Structure Deep Dive\n",
    "\n",
    "Inspect EDF headers across corpora: channels, sampling rates, durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Sample N files from each available corpus to characterize EDF properties\nN_SAMPLE = 50\n\nedf_stats = []\nfor inv in inventories:\n    corpus_name = inv['corpus']\n    corpus_path = corpora_config[corpus_name]\n    all_edfs = sorted(glob.glob(str(corpus_path / '**/*.edf'), recursive=True))\n    if not all_edfs:\n        continue\n    sample = np.random.choice(all_edfs, min(N_SAMPLE, len(all_edfs)), replace=False)\n\n    for edf_path in tqdm(sample, desc=corpus_name):\n        info = inspect_edf(edf_path)\n        if 'error' not in info:\n            edf_stats.append({\n                'corpus': corpus_name,\n                'n_channels': info['n_channels'],\n                'duration_min': info['duration_sec'] / 60,\n                'sfreq': info['sample_freqs'][0] if info['sample_freqs'] else None,\n                'path': edf_path,\n            })\n\nedf_df = pd.DataFrame(edf_stats)\nif not edf_df.empty:\n    print(f\"\\nSampled {len(edf_df)} EDF files across {edf_df['corpus'].nunique()} corpora\")\n    display(edf_df.groupby('corpus').agg({\n        'n_channels': ['mean', 'min', 'max'],\n        'duration_min': ['mean', 'min', 'max'],\n        'sfreq': ['mean', 'min', 'max']\n    }).round(1))\nelse:\n    print(\"No EDF files could be read — corpora may still be downloading.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize distributions\nif not edf_df.empty:\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n    for corpus in edf_df['corpus'].unique():\n        subset = edf_df[edf_df['corpus'] == corpus]\n        axes[0].hist(subset['n_channels'], bins=20, alpha=0.6, label=corpus)\n        axes[1].hist(subset['duration_min'], bins=20, alpha=0.6, label=corpus)\n        axes[2].hist(subset['sfreq'], bins=20, alpha=0.6, label=corpus)\n\n    axes[0].set_xlabel('Number of Channels')\n    axes[0].set_title('Channel Count Distribution')\n    axes[0].legend()\n    axes[1].set_xlabel('Duration (minutes)')\n    axes[1].set_title('Recording Duration Distribution')\n    axes[2].set_xlabel('Sampling Frequency (Hz)')\n    axes[2].set_title('Sampling Rate Distribution')\n\n    plt.tight_layout()\n    plt.savefig(str(DATA_ROOT.parent / 'edf_distributions.png'), bbox_inches='tight')\n    plt.show()\nelse:\n    print(\"No EDF data to plot — skipping distributions.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Signal Visualization\n",
    "\n",
    "Load and plot actual EEG signals from each corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot one sample from each available corpus\nfor inv in inventories:\n    if not inv['sample_edf']:\n        continue\n    edf_path = inv['sample_edf']\n    corpus = inv['corpus']\n    print(f\"\\n{'='*80}\")\n    print(f\"Corpus: {corpus} | File: {Path(edf_path).name}\")\n\n    raw = safe_read_raw_edf(edf_path)\n    if raw is None:\n        print(f\"  Could not read {Path(edf_path).name} (file may be incomplete)\")\n        continue\n    print(f\"  Channels: {raw.info['nchan']}, Sfreq: {raw.info['sfreq']} Hz, Duration: {raw.times[-1]:.0f}s\")\n\n    # Apply TCP montage\n    tcp_raw = apply_tcp_montage(raw)\n    if tcp_raw is not None:\n        fig = plot_eeg_segment(tcp_raw, start_sec=10, duration_sec=10,\n                               title=f'{corpus}: {Path(edf_path).stem} (TCP montage, 10s window)')\n        plt.show()\n    else:\n        print(\"  Could not apply TCP montage, plotting raw channels\")\n        fig = plot_eeg_segment(raw, start_sec=10, duration_sec=10,\n                               title=f'{corpus}: {Path(edf_path).stem} (raw channels, 10s window)')\n        plt.show()\n\nif not inventories:\n    print(\"No corpora available to plot.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Annotation Analysis by Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 TUAR - Artifact Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "tuar_path = DATA_ROOT / 'tuar'\nif tuar_path.exists():\n    tuar_csvs = sorted(tuar_path.rglob('*.csv'))\n    tuar_csvs = [f for f in tuar_csvs if '_seiz' not in f.name]\n\n    if tuar_csvs:\n        all_labels = []\n        all_durations = []\n        for csv_path in tqdm(tuar_csvs[:100], desc='TUAR annotations'):\n            df, meta = load_csv_annotations(csv_path)\n            if 'label' in df.columns and 'start_time' in df.columns and 'stop_time' in df.columns:\n                df['duration'] = df['stop_time'] - df['start_time']\n                all_labels.extend(df['label'].tolist())\n                all_durations.extend(df['duration'].tolist())\n\n        label_counts = Counter(all_labels)\n        print(f\"TUAR: {len(tuar_csvs)} annotation files, {len(all_labels)} total events\")\n\n        if label_counts and all_durations:\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n            labels, counts = zip(*label_counts.most_common(15))\n            ax1.barh(range(len(labels)), counts, color='steelblue')\n            ax1.set_yticks(range(len(labels)))\n            ax1.set_yticklabels(labels)\n            ax1.set_xlabel('Count')\n            ax1.set_title('TUAR: Artifact Type Distribution')\n            ax1.invert_yaxis()\n\n            ax2.hist(all_durations, bins=50, color='coral', edgecolor='white')\n            ax2.set_xlabel('Duration (seconds)')\n            ax2.set_title('TUAR: Artifact Event Duration')\n            ax2.set_xlim(0, min(30, np.percentile(all_durations, 99)))\n            plt.tight_layout()\n            plt.show()\n    else:\n        print(\"TUAR directory exists but no CSV annotations yet (download in progress?)\")\nelse:\n    print(\"TUAR not available yet\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 TUSZ - Seizure Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "tusz_path = DATA_ROOT / 'tusz'\nif tusz_path.exists():\n    csv_bi_candidates = list(tusz_path.rglob('*.csv_bi'))\n    if csv_bi_candidates:\n        seizure_stats = {'train': defaultdict(int), 'dev': defaultdict(int), 'eval': defaultdict(int)}\n\n        for split in ['train', 'dev', 'eval']:\n            split_path = tusz_path / 'edf' / split\n            if not split_path.exists():\n                continue\n            csv_bi_files = sorted(split_path.rglob('*.csv_bi'))\n\n            for csv_path in tqdm(csv_bi_files[:200], desc=f'TUSZ {split}'):\n                df, meta = load_csv_annotations(csv_path)\n                if 'label' in df.columns:\n                    for label in df['label'].unique():\n                        seizure_stats[split][label] += (df['label'] == label).sum()\n\n        print(\"\\nTUSZ Label Distribution (sampled):\")\n        for split, counts in seizure_stats.items():\n            total = sum(counts.values())\n            if total > 0:\n                print(f\"  {split}: {dict(counts)} (total: {total})\")\n\n        # Also check multi-class annotations\n        edf_dir = tusz_path / 'edf'\n        if edf_dir.exists():\n            csv_files = sorted(edf_dir.rglob('*.csv'))\n            csv_files = [f for f in csv_files if not f.name.endswith('.csv_bi')]\n            seizure_types = Counter()\n            for csv_path in tqdm(csv_files[:300], desc='TUSZ seizure types'):\n                df, _ = load_csv_annotations(csv_path)\n                if 'label' in df.columns:\n                    for label in df['label']:\n                        if label != 'bckg':\n                            seizure_types[label] += 1\n\n            if seizure_types:\n                print(f\"\\nSeizure type distribution (from {min(300, len(csv_files))} files):\")\n                for label, count in seizure_types.most_common():\n                    print(f\"  {label}: {count}\")\n    else:\n        print(\"TUSZ directory exists but no .csv_bi annotations yet (download in progress?)\")\nelse:\n    print(\"TUSZ not available yet\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 TUAB - Normal/Abnormal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "tuab_path = DATA_ROOT / 'tuab'\nif tuab_path.exists():\n    edf_candidates = list(tuab_path.rglob('*.edf'))\n    if edf_candidates:\n        tuab_stats = defaultdict(lambda: defaultdict(int))\n\n        for split in ['train', 'eval']:\n            for label in ['normal', 'abnormal']:\n                label_path = tuab_path / 'edf' / split / label\n                if label_path.exists():\n                    n_files = len(list(label_path.rglob('*.edf')))\n                    tuab_stats[split][label] = n_files\n\n        if tuab_stats:\n            print(\"TUAB Normal/Abnormal Distribution:\")\n            tuab_summary = pd.DataFrame(tuab_stats).T\n            if 'abnormal' in tuab_summary.columns and 'normal' in tuab_summary.columns:\n                tuab_summary['total'] = tuab_summary.sum(axis=1)\n                tuab_summary['abnormal_pct'] = (tuab_summary['abnormal'] / tuab_summary['total'] * 100).round(1)\n            display(tuab_summary)\n\n        # Duration distribution by class\n        dur_data = []\n        for split in ['train', 'eval']:\n            for label in ['normal', 'abnormal']:\n                label_path = tuab_path / 'edf' / split / label\n                if not label_path.exists():\n                    continue\n                edfs = sorted(label_path.rglob('*.edf'))\n                for edf in edfs[:50]:\n                    info = inspect_edf(edf)\n                    if 'error' not in info:\n                        dur_data.append({'split': split, 'label': label, 'duration_min': info['duration_sec']/60})\n\n        if dur_data:\n            dur_df = pd.DataFrame(dur_data)\n            fig, ax = plt.subplots(figsize=(10, 5))\n            for label in ['normal', 'abnormal']:\n                subset = dur_df[dur_df['label'] == label]\n                if not subset.empty:\n                    ax.hist(subset['duration_min'], bins=30, alpha=0.6, label=label)\n            ax.set_xlabel('Duration (minutes)')\n            ax.set_title('TUAB: Recording Duration by Class')\n            ax.legend()\n            plt.tight_layout()\n            plt.show()\n    else:\n        print(\"TUAB directory exists but no EDF files yet (download in progress?)\")\nelse:\n    print(\"TUAB not available yet\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 TUEV - Event Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "tuev_path = DATA_ROOT / 'tuev'\nif tuev_path.exists():\n    rec_files = sorted(tuev_path.rglob('*.rec'))\n    if rec_files:\n        event_counts = Counter()\n\n        for rec_path in tqdm(rec_files[:200], desc='TUEV events'):\n            df = load_rec_annotations(rec_path)\n            if not df.empty:\n                event_counts.update(df['label'].tolist())\n\n        print(f\"TUEV: {len(rec_files)} .rec files\")\n        print(\"Event distribution:\")\n\n        if event_counts:\n            fig, ax = plt.subplots(figsize=(10, 4))\n            labels, counts = zip(*event_counts.most_common())\n            colors = {'spsw': '#e74c3c', 'gped': '#e67e22', 'pled': '#f39c12',\n                      'eyem': '#3498db', 'artf': '#95a5a6', 'bckg': '#2ecc71'}\n            bar_colors = [colors.get(l, '#95a5a6') for l in labels]\n            ax.bar(labels, counts, color=bar_colors)\n            ax.set_ylabel('Count')\n            ax.set_title('TUEV: Event Type Distribution')\n            for i, (l, c) in enumerate(zip(labels, counts)):\n                ax.text(i, c + max(counts)*0.01, str(c), ha='center', fontsize=9)\n            plt.tight_layout()\n            plt.show()\n    else:\n        print(\"TUEV directory exists but no .rec files yet (download in progress?)\")\nelse:\n    print(\"TUEV not available yet\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 TUSL - Slowing Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "tusl_path = DATA_ROOT / 'tusl'\nif tusl_path.exists():\n    tse_files = sorted(tusl_path.rglob('*.tse'))\n    tse_agg_files = sorted(tusl_path.rglob('*.tse_agg'))\n\n    if tse_files:\n        label_counts = Counter()\n        for tse_path in tqdm(tse_files, desc='TUSL annotations'):\n            df = load_tse_annotations(tse_path)\n            if not df.empty:\n                label_counts.update(df['label'].tolist())\n\n        print(f\"TUSL: {len(tse_files)} .tse files, {len(tse_agg_files)} .tse_agg files\")\n        print(f\"Labels: {dict(label_counts)}\")\n\n        if label_counts:\n            fig, ax = plt.subplots(figsize=(8, 4))\n            labels, counts = zip(*label_counts.most_common())\n            colors = {'seiz': '#e74c3c', 'slow': '#f39c12', 'bckg': '#2ecc71'}\n            ax.bar(labels, counts, color=[colors.get(l, '#95a5a6') for l in labels])\n            ax.set_title('TUSL: Label Distribution')\n            ax.set_ylabel('Count')\n            plt.tight_layout()\n            plt.show()\n    else:\n        print(\"TUSL directory exists but no .tse files yet (download in progress?)\")\nelse:\n    print(\"TUSL not available\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 TUEP - Epilepsy Corpus with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "tuep_path = DATA_ROOT / 'tuep'\nif tuep_path.exists():\n    # Check for metadata spreadsheet\n    metadata_path = tuep_path / 'DOCS' / 'metadata_v00r.xlsx'\n    if metadata_path.exists():\n        try:\n            meta_df = pd.read_excel(metadata_path)\n            print(f\"TUEP Metadata: {len(meta_df)} rows, {len(meta_df.columns)} columns\")\n            print(f\"Columns: {list(meta_df.columns)}\")\n            display(meta_df.head(10))\n        except Exception as e:\n            print(f\"Could not read metadata: {e}\")\n\n    # Count files per class\n    found_any = False\n    for cls in ['00_epilepsy', '01_no_epilepsy']:\n        cls_path = tuep_path / cls\n        if cls_path.exists():\n            found_any = True\n            n_edfs = len(list(cls_path.rglob('*.edf')))\n            n_subjects = len([d for d in cls_path.iterdir() if d.is_dir()]) if cls_path.is_dir() else 0\n            print(f\"  {cls}: {n_edfs} EDF files, {n_subjects} subjects\")\n    if not found_any:\n        print(\"TUEP directory exists but class folders not found yet (download in progress?)\")\nelse:\n    print(\"TUEP not available\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Signal Quality & Spectral Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Pick a representative file — try TUSL first (smallest), fall back to any available corpus\nsample_edfs = sorted(glob.glob(str(DATA_ROOT / 'tusl' / '**/*.edf'), recursive=True))\nif not sample_edfs and inventories:\n    # Fall back to first corpus that has an EDF\n    for inv in inventories:\n        if inv['sample_edf']:\n            sample_edfs = [inv['sample_edf']]\n            break\n\nif sample_edfs:\n    sample_edf = sample_edfs[0]\n    raw = safe_read_raw_edf(sample_edf)\n\n    if raw is not None:\n        tcp = apply_tcp_montage(raw)\n\n        if tcp is not None:\n            fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n\n            # PSD\n            psd = tcp.compute_psd(fmin=0.5, fmax=50, method='welch', verbose=False)\n            psd.plot(axes=axes[0], show=False, spatial_colors=True)\n            axes[0].set_title('Power Spectral Density (TCP montage)')\n\n            # Spectrogram of one channel\n            data = tcp.get_data(picks=[0])[0]\n            sfreq = tcp.info['sfreq']\n            axes[1].specgram(data, NFFT=int(sfreq*2), Fs=sfreq, noverlap=int(sfreq),\n                             cmap='viridis', vmin=-30, vmax=10)\n            axes[1].set_ylabel('Frequency (Hz)')\n            axes[1].set_xlabel('Time (s)')\n            axes[1].set_ylim(0, 50)\n            axes[1].set_title(f'Spectrogram: {tcp.ch_names[0]}')\n\n            plt.tight_layout()\n            plt.savefig(str(DATA_ROOT.parent / 'spectral_analysis.png'), bbox_inches='tight')\n            plt.show()\n        else:\n            print(\"Could not apply TCP montage to sample file\")\n    else:\n        print(f\"Could not read {sample_edf} (file may be incomplete)\")\nelse:\n    print(\"No EDF files found — skipping spectral analysis.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-Corpus Comparison\n",
    "\n",
    "Compare key properties across all available corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Summarize all findings\nif inventories:\n    summary_data = []\n    for inv in inventories:\n        corpus = inv['corpus']\n        corpus_edfs = edf_df[edf_df['corpus'] == corpus] if not edf_df.empty and 'corpus' in edf_df.columns else pd.DataFrame()\n\n        summary_data.append({\n            'Corpus': corpus,\n            'EDF Files': inv['edf_files'],\n            'Subjects': inv['subjects'],\n            'Annotation Files': inv['csv_files'] + inv['tse_files'] + inv['rec_files'] + inv['lab_files'],\n            'Avg Duration (min)': corpus_edfs['duration_min'].mean() if not corpus_edfs.empty else None,\n            'Avg Channels': corpus_edfs['n_channels'].mean() if not corpus_edfs.empty else None,\n            'Primary Sfreq (Hz)': corpus_edfs['sfreq'].mode().iloc[0] if not corpus_edfs.empty and not corpus_edfs['sfreq'].mode().empty else None,\n            'Montages': ', '.join(inv['montages'].keys()) if inv['montages'] else 'N/A',\n        })\n\n    summary_df = pd.DataFrame(summary_data).set_index('Corpus')\n    display(summary_df)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"EXPLORATION COMPLETE\")\nprint(\"=\"*80)\nif inventories:\n    print(f\"Corpora explored: {len(inventories)}\")\n    print(f\"Total EDF files across corpora: {sum(inv['edf_files'] for inv in inventories)}\")\n    print(f\"Total unique subjects: {sum(inv['subjects'] for inv in inventories)} (with overlap between corpora)\")\nelse:\n    print(\"No corpora available yet. Re-run after downloading data.\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Interactive EEG Explorer\n\nSelect a corpus, browse subjects, preview file info, and open recordings — all from dropdowns.\n- **Plot in Notebook**: inline 10-second TCP montage preview\n- **Open Qt Viewer**: full scrollable EEG browser in a separate window (requires display/X11)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import ipywidgets as widgets\nfrom IPython.display import display, clear_output, HTML\n\n# ── Corpus metadata ──────────────────────────────────────────────────────────\nCORPUS_META = {\n    'TUSL': {'desc': 'Slowing vs Seizure differentiation', 'size': '1.5 GB',\n             'version': 'v2.0.1', 'labels': 'seiz, slow, bckg', 'ann_ext': '.tse'},\n    'TUAR': {'desc': 'Per-channel artifact detection', 'size': '5.4 GB',\n             'version': 'v3.0.1', 'labels': 'eyem, chew, shiv, musc, elec, ...', 'ann_ext': '.csv'},\n    'TUEV': {'desc': '6-class EEG event classification', 'size': '19 GB',\n             'version': 'v2.0.1', 'labels': 'spsw, gped, pled, eyem, artf, bckg', 'ann_ext': '.rec'},\n    'TUEP': {'desc': 'Epilepsy / no-epilepsy diagnosis', 'size': '35 GB',\n             'version': 'v3.0.0', 'labels': 'epilepsy, no_epilepsy', 'ann_ext': '.csv'},\n    'TUAB': {'desc': 'Binary normal / abnormal EEG', 'size': '58 GB',\n             'version': 'v3.0.1', 'labels': 'normal, abnormal (by folder)', 'ann_ext': None},\n    'TUSZ': {'desc': 'Seizure detection benchmark', 'size': '81 GB',\n             'version': 'v2.0.3', 'labels': 'seiz, bckg (+ seizure types)', 'ann_ext': '.csv_bi'},\n    'TUEG': {'desc': 'Full TUH EEG Corpus (unlabeled)', 'size': '1,639 GB',\n             'version': 'v2.0.1', 'labels': 'N/A', 'ann_ext': None},\n}\n\n# ── Lazy per-subject index with cache ────────────────────────────────────────\n_subject_cache = {}\n\ndef _scan_subjects(corpus_name):\n    \"\"\"Scan corpus EDF files grouped by subject. Cached after first call.\"\"\"\n    if corpus_name in _subject_cache:\n        return _subject_cache[corpus_name]\n    path = corpora_config.get(corpus_name)\n    if not path or not path.exists():\n        return {}\n    subjects = {}\n    for edf in sorted(path.rglob('*.edf')):\n        meta = parse_tuh_path(edf)\n        if meta:\n            subjects.setdefault(meta['subject_id'], []).append(meta)\n    _subject_cache[corpus_name] = subjects\n    return subjects\n\n# ── Available corpora (from inventory, already computed) ─────────────────────\n_available = [inv['corpus'] for inv in inventories] if inventories else []\n\n# ── Widgets ──────────────────────────────────────────────────────────────────\n_style = {'description_width': '70px'}\n\ncorpus_dd = widgets.Dropdown(\n    options=[''] + _available,\n    value='',\n    description='Corpus:',\n    style=_style,\n    layout=widgets.Layout(width='260px'),\n)\nsubject_dd = widgets.Dropdown(\n    options=[''],\n    value='',\n    description='Subject:',\n    style=_style,\n    layout=widgets.Layout(width='260px'),\n)\nfile_dd = widgets.Dropdown(\n    options=[''],\n    value='',\n    description='File:',\n    style=_style,\n    layout=widgets.Layout(width='420px'),\n)\n\nplot_btn = widgets.Button(\n    description=' Plot in Notebook',\n    icon='line-chart',\n    button_style='info',\n    layout=widgets.Layout(width='180px', height='36px'),\n)\nviewer_btn = widgets.Button(\n    description=' Open Qt Viewer',\n    icon='desktop',\n    button_style='success',\n    layout=widgets.Layout(width='180px', height='36px'),\n)\n\noverview_out = widgets.Output(layout=widgets.Layout(\n    border='1px solid #ccc', padding='10px', min_height='120px', width='100%',\n))\nfile_info_out = widgets.Output(layout=widgets.Layout(\n    border='1px solid #ccc', padding='10px', min_height='120px', width='100%',\n))\nplot_out = widgets.Output(layout=widgets.Layout(width='100%'))\nstatus_label = widgets.HTML(value='<i>Select a corpus to begin.</i>')\n\n# ── Internal state ───────────────────────────────────────────────────────────\n_state = {'subjects': {}, 'files': [], 'raw': None, 'tcp': None, 'path': None}\n\n# ── Callbacks ────────────────────────────────────────────────────────────────\ndef _on_corpus(change):\n    corpus = change['new']\n    # Reset downstream\n    _state['raw'] = _state['tcp'] = _state['path'] = None\n    file_dd.options = ['']\n    file_dd.value = ''\n    with file_info_out:\n        clear_output()\n    with plot_out:\n        clear_output()\n\n    if not corpus:\n        subject_dd.options = ['']\n        with overview_out:\n            clear_output()\n        status_label.value = '<i>Select a corpus to begin.</i>'\n        return\n\n    status_label.value = f'<i>Scanning {corpus} subjects...</i>'\n    subjects = _scan_subjects(corpus)\n    _state['subjects'] = subjects\n\n    # Populate subject dropdown\n    sorted_sids = sorted(subjects.keys())\n    subject_dd.options = [''] + sorted_sids\n    subject_dd.value = ''\n\n    # Overview panel\n    meta = CORPUS_META.get(corpus, {})\n    inv = next((i for i in inventories if i['corpus'] == corpus), None)\n    with overview_out:\n        clear_output(wait=True)\n        lines = [\n            f\"<b>{corpus}</b> {meta.get('version', '')} &mdash; {meta.get('size', '?')}\",\n            f\"<i>{meta.get('desc', '')}</i>\",\n            f\"<b>EDF files:</b> {inv['edf_files'] if inv else '?'} &nbsp;|&nbsp; \"\n            f\"<b>Subjects:</b> {len(sorted_sids)}\",\n            f\"<b>Labels:</b> {meta.get('labels', 'N/A')}\",\n        ]\n        if inv and inv['montages']:\n            montage_str = ', '.join(f\"{k} ({v})\" for k, v in inv['montages'].items())\n            lines.append(f\"<b>Montages:</b> {montage_str}\")\n        display(HTML('<br>'.join(lines)))\n\n    status_label.value = f'<b>{corpus}</b>: {len(sorted_sids)} subjects ready.'\n\n\ndef _on_subject(change):\n    sid = change['new']\n    _state['raw'] = _state['tcp'] = _state['path'] = None\n    with file_info_out:\n        clear_output()\n    with plot_out:\n        clear_output()\n\n    if not sid:\n        file_dd.options = ['']\n        return\n\n    files = _state['subjects'].get(sid, [])\n    _state['files'] = files\n    labels = [\n        f\"{Path(f['path']).stem}  ({f['montage'] or '?'})\"\n        for f in files\n    ]\n    file_dd.options = [''] + labels\n    file_dd.value = ''\n    status_label.value = f'Subject <b>{sid}</b>: {len(files)} file(s).'\n\n\ndef _on_file(change):\n    sel = change['new']\n    _state['raw'] = _state['tcp'] = _state['path'] = None\n    with plot_out:\n        clear_output()\n\n    if not sel:\n        with file_info_out:\n            clear_output()\n        return\n\n    idx = (file_dd.options).index(sel) - 1  # offset for leading ''\n    meta = _state['files'][idx]\n    edf_path = meta['path']\n    _state['path'] = edf_path\n\n    info = inspect_edf(edf_path)\n    with file_info_out:\n        clear_output(wait=True)\n        if 'error' in info:\n            display(HTML(f\"<span style='color:red'>Cannot read file (may be incomplete):</span><br>{info['error']}\"))\n            return\n        dur_min = info['duration_sec'] / 60\n        sfreqs = info['sample_freqs']\n        sfreq_str = f\"{sfreqs[0]:.0f} Hz\" if sfreqs else '?'\n        lines = [\n            f\"<b>{Path(edf_path).name}</b>\",\n            f\"<b>Channels:</b> {info['n_channels']} &nbsp;|&nbsp; \"\n            f\"<b>Sfreq:</b> {sfreq_str} &nbsp;|&nbsp; \"\n            f\"<b>Duration:</b> {dur_min:.1f} min\",\n            f\"<b>Montage:</b> {meta['montage'] or 'unknown'}\",\n            f\"<b>Subject:</b> {meta['subject_id']} &nbsp;|&nbsp; \"\n            f\"<b>Session:</b> s{meta['session_num']:03d} &nbsp;|&nbsp; \"\n            f\"<b>Token:</b> t{meta['token_num']:03d}\",\n        ]\n        # Check for annotation files alongside the EDF\n        edf_p = Path(edf_path)\n        ann_exts = ['.csv', '.csv_bi', '.tse', '.tse_agg', '.lbl', '.lbl_agg', '.rec', '.lab']\n        found_ann = [ext for ext in ann_exts if edf_p.with_suffix(ext).exists()]\n        if found_ann:\n            lines.append(f\"<b>Annotations:</b> {', '.join(found_ann)}\")\n        else:\n            lines.append(\"<b>Annotations:</b> none found\")\n        display(HTML('<br>'.join(lines)))\n\n    status_label.value = f'Ready: {Path(edf_path).name}'\n\n\ndef _on_plot(btn):\n    if not _state['path']:\n        with plot_out:\n            clear_output(wait=True)\n            print(\"Select a file first.\")\n        return\n\n    with plot_out:\n        clear_output(wait=True)\n        status_label.value = '<i>Loading EDF...</i>'\n        raw = safe_read_raw_edf(_state['path'])\n        if raw is None:\n            print(f\"Could not read file (may be incomplete).\")\n            status_label.value = 'Load failed.'\n            return\n        _state['raw'] = raw\n        tcp = apply_tcp_montage(raw)\n        _state['tcp'] = tcp\n        target = tcp if tcp is not None else raw\n        tag = 'TCP montage' if tcp is not None else 'raw channels'\n\n        # Pick a start 10s in if recording is long enough\n        max_start = max(0, target.times[-1] - 10)\n        start = min(10.0, max_start)\n\n        fig = plot_eeg_segment(target, start_sec=start, duration_sec=10,\n                               title=f'{Path(_state[\"path\"]).stem} ({tag})')\n        plt.show()\n        status_label.value = f'Plotted {Path(_state[\"path\"]).name} ({tag}).'\n\n\ndef _on_viewer(btn):\n    if not _state['path']:\n        status_label.value = '<span style=\"color:orange\">Select a file first.</span>'\n        return\n\n    status_label.value = '<i>Loading into Qt viewer...</i>'\n    raw = _state.get('raw') or safe_read_raw_edf(_state['path'])\n    if raw is None:\n        status_label.value = '<span style=\"color:red\">Could not read file.</span>'\n        return\n    _state['raw'] = raw\n\n    tcp = _state.get('tcp') or apply_tcp_montage(raw)\n    target = tcp if tcp is not None else raw\n\n    try:\n        mne.viz.set_browser_backend('qt')\n        target.plot(block=False, title=Path(_state['path']).stem)\n        status_label.value = f'Qt viewer opened for {Path(_state[\"path\"]).name}.'\n    except Exception as e:\n        status_label.value = f'<span style=\"color:red\">Qt viewer failed: {e}</span>'\n\n\n# ── Wire up ──────────────────────────────────────────────────────────────────\ncorpus_dd.observe(_on_corpus, names='value')\nsubject_dd.observe(_on_subject, names='value')\nfile_dd.observe(_on_file, names='value')\nplot_btn.on_click(_on_plot)\nviewer_btn.on_click(_on_viewer)\n\n# ── Layout ───────────────────────────────────────────────────────────────────\nselectors = widgets.HBox([corpus_dd, subject_dd, file_dd],\n                         layout=widgets.Layout(gap='8px'))\nbuttons = widgets.HBox([plot_btn, viewer_btn],\n                       layout=widgets.Layout(gap='8px'))\npanels = widgets.HBox([\n    widgets.VBox([widgets.HTML('<b>Corpus Overview</b>'), overview_out],\n                 layout=widgets.Layout(width='50%')),\n    widgets.VBox([widgets.HTML('<b>File Details</b>'), file_info_out],\n                 layout=widgets.Layout(width='50%')),\n], layout=widgets.Layout(gap='12px'))\n\nui = widgets.VBox([\n    selectors,\n    panels,\n    widgets.HBox([buttons, status_label], layout=widgets.Layout(gap='16px', align_items='center')),\n    plot_out,\n], layout=widgets.Layout(gap='10px', padding='8px'))\n\ndisplay(ui)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}